---
title: "LinearModel"
author: "Michelle Cervantes"
date: "11/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
  
```{r}
dataF <- read.csv(file="http://onlinestatbook.com/case_studies_rvls/physical_strength/data.txt",sep="", header=TRUE)
```
  
```{r include=FALSE}
require(tidyverse)
require(tigerstats)
require(knitr)
```
  
  
### Now with ggplot - first select the basic data   

```{r}
basicNN <- ggplot(dataF,aes(y=SIMS,x=ARM))
```
  
### Now add in scatterplot   
  
```{r}
basicNN + geom_point()+ geom_smooth(method=lm)
```

Every dot in this chart is either above or below that blue line, which tells me that many of those dots do not align perfectly with an adjusted r-squared value. This model is still a 47% improved model in comparison to the other way it is built.
```{r}
basicNN <- ggplot(dataF,aes(y=SIMS,x=GRIP))
```
  
### Now add in scatterplot   
  
```{r}
basicNN + geom_point()+ geom_smooth(method=lm)
```

The plot of SIMS versus GRIP + ARM will look line a plane in a 3 dimensional space and right now we do not have the right tools to plot it.

### Inferential  (Build linear model)   
  
```{r}
model.1 <- lm(SIMS~ARM,data=dataF)
summary.lm(model.1)
```

This particular model is explaining about 47% of the variation more than the mean model did. 

```{r}
model.2 <- lm(SIMS~GRIP,data=dataF)
summary.lm(model.2)
``` 

Based off all the data shown, the model of SIMS and ARM is better than the model with GRIP.

```{r}
model.3 <- lm(SIMS~GRIP+ARM,data=dataF)
summary.lm(model.3)
``` 

Looking at this chart we can see that the adjusted r-squared is 0.5358 which is higher than model 1 or 2. This tells us that this model explains more of the variation than either of the previous two did and so far this is the better model. 

### now predict 

```{r}
new <- data.frame(ARM=88,GRIP=94)
predict.lm(model.1,new)
predict(model.1,new,interval="prediction")
```
The 95% confidence interval is somewhere between the -1.7 to the positive 3.13


```{r}
new <- data.frame(ARM=88,GRIP=94)
predict.lm(model.2,new)
predict(model.2,new,interval="prediction")
```
The prediction here shows the values range from -0.536 to positive 2.035

```{r}
new <- data.frame(ARM=88,GRIP=94)
predict.lm(model.3,new)
predict(model.3,new,interval="prediction")
```
Finally this prediction shows the values range from 0.149 to 2.43 which demonstrates how this model is the best because it has absolutely no negative values like the other two did.

```{r}
anova(model.1,model.3)
```

After looking at all of our data we collected we can tell that we have a very low p-value therefore we reject the null hypothesis. The null hypothesis tells us that there isn't any difference in how well model 1 explains ARM and how well model 2 explains ARM.

### Conclusion   

We can now conclude that model 2 is the worst one, Model 1 is the second best one and model 3 is the best model based on what's going with the adjusted r-squared and our anova test. Model 3 is doing a much better job than the other models. 
